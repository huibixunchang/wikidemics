{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Influenza Related Data via the DELPHI Epidata API\n",
    "### Purpose of this notebook\n",
    "* Gather the Wikipedia Pageviews and ILInet data from the DELPHI epidata API\n",
    "* Store the data into pandas DataFrames to facilitate analysis (in other notebooks)\n",
    "* Create a DataFrame that maps Epiweeks to their corresponding Datetimes\n",
    "\n",
    "*The relevant computed variables are stored in iPython's local data store to avoid recomputation. These variables can be accessed from other notebooks using the %store magic command*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import epidata as delphi\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "%store -r pageViewResps\n",
    "%store -r wILIresp\n",
    "%store -r pageViews\n",
    "%store -r wILI\n",
    "%store -r epiweeksDf\n",
    "\n",
    "definedVariables = set(list(globals().keys()) + list(vars().keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Wikipedia Page Views for Flu Related Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pageViewResps\n"
     ]
    }
   ],
   "source": [
    "if 'pageViewResps' not in definedVariables:\n",
    "    \n",
    "    print(\"Calling the DELPHI epidata API for wikipedia pageviews\")\n",
    "    \n",
    "    epidata = delphi.Epidata() # interface to CMU delphi API\n",
    "\n",
    "    with open('./data/allarticles.txt') as f:\n",
    "        fluRelatedArticles = [article.strip() for article in f]\n",
    "    years = range(2008, 2017) # 2008 - 2016 full years\n",
    "    epiranges = [ epidata.range(int(str(yr) + '01'), int(str(yr) + '52')) for yr in years]\n",
    "    pageViewResps = []\n",
    "    # API calls to the delphi epidata API\n",
    "    for epiyear in epiranges:\n",
    "        resp = epidata.wiki(fluRelatedArticles, epiweeks=epiyear)['epidata']\n",
    "        pageViewResps.extend(resp)\n",
    "        time.sleep(15)\n",
    "    %store pageViewResps\n",
    "else:\n",
    "    print(\"Found pageViewResps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting state level ILInet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found wILIresp\n"
     ]
    }
   ],
   "source": [
    "if 'wILIresp' not in definedVariables:\n",
    "    \n",
    "    print(\"Calling the DELPHI epidata API for ILInet data\")\n",
    "    \n",
    "    wILIresp = epidata.fluview('nat', epidata.range(200801, 201652))['epidata']\n",
    "    %store wILIresp\n",
    "else:\n",
    "    print(\"Found wILIresp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting pageViews API response data in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pageViews\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>influenzavirus_c</th>\n",
       "      <th>influenza_a_virus_subtype_h1n1</th>\n",
       "      <th>rhinorrhea</th>\n",
       "      <th>sore_throat</th>\n",
       "      <th>equine_influenza</th>\n",
       "      <th>swine_influenza</th>\n",
       "      <th>influenza_b_virus</th>\n",
       "      <th>influenza_a_virus_subtype_h3n2</th>\n",
       "      <th>antiviral_drugs</th>\n",
       "      <th>influenza_a_virus_subtype_h7n7</th>\n",
       "      <th>...</th>\n",
       "      <th>fatigue_(medical)</th>\n",
       "      <th>cat_flu</th>\n",
       "      <th>paracetamol</th>\n",
       "      <th>influenzavirus_a</th>\n",
       "      <th>influenza</th>\n",
       "      <th>influenzalike_illness</th>\n",
       "      <th>human_flu</th>\n",
       "      <th>viral_neuraminidase</th>\n",
       "      <th>influenza_a_virus_subtype_h7n2</th>\n",
       "      <th>avian_influenza</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200801</th>\n",
       "      <td>209</td>\n",
       "      <td>34</td>\n",
       "      <td>1511</td>\n",
       "      <td>3513</td>\n",
       "      <td>187</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>242</td>\n",
       "      <td>135</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>957</td>\n",
       "      <td>319</td>\n",
       "      <td>24246</td>\n",
       "      <td>1500</td>\n",
       "      <td>17568</td>\n",
       "      <td>0</td>\n",
       "      <td>350</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200802</th>\n",
       "      <td>243</td>\n",
       "      <td>33</td>\n",
       "      <td>1821</td>\n",
       "      <td>3841</td>\n",
       "      <td>212</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>260</td>\n",
       "      <td>185</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>1045</td>\n",
       "      <td>339</td>\n",
       "      <td>24699</td>\n",
       "      <td>2229</td>\n",
       "      <td>23338</td>\n",
       "      <td>0</td>\n",
       "      <td>453</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>4870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200803</th>\n",
       "      <td>228</td>\n",
       "      <td>45</td>\n",
       "      <td>1751</td>\n",
       "      <td>3549</td>\n",
       "      <td>268</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>97</td>\n",
       "      <td>193</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>960</td>\n",
       "      <td>291</td>\n",
       "      <td>22948</td>\n",
       "      <td>2488</td>\n",
       "      <td>22742</td>\n",
       "      <td>0</td>\n",
       "      <td>534</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>5478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200804</th>\n",
       "      <td>247</td>\n",
       "      <td>40</td>\n",
       "      <td>1786</td>\n",
       "      <td>3736</td>\n",
       "      <td>297</td>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>171</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>440</td>\n",
       "      <td>298</td>\n",
       "      <td>19869</td>\n",
       "      <td>3295</td>\n",
       "      <td>23488</td>\n",
       "      <td>0</td>\n",
       "      <td>577</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>6522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200805</th>\n",
       "      <td>341</td>\n",
       "      <td>64</td>\n",
       "      <td>1707</td>\n",
       "      <td>3859</td>\n",
       "      <td>230</td>\n",
       "      <td>38</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>202</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1174</td>\n",
       "      <td>354</td>\n",
       "      <td>19414</td>\n",
       "      <td>4557</td>\n",
       "      <td>29240</td>\n",
       "      <td>0</td>\n",
       "      <td>735</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>6773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        influenzavirus_c  influenza_a_virus_subtype_h1n1  rhinorrhea  \\\n",
       "200801               209                              34        1511   \n",
       "200802               243                              33        1821   \n",
       "200803               228                              45        1751   \n",
       "200804               247                              40        1786   \n",
       "200805               341                              64        1707   \n",
       "\n",
       "        sore_throat  equine_influenza  swine_influenza  influenza_b_virus  \\\n",
       "200801         3513               187               17                 14   \n",
       "200802         3841               212               21                 12   \n",
       "200803         3549               268               16                 18   \n",
       "200804         3736               297               24                 13   \n",
       "200805         3859               230               38                 22   \n",
       "\n",
       "        influenza_a_virus_subtype_h3n2  antiviral_drugs  \\\n",
       "200801                             242              135   \n",
       "200802                             260              185   \n",
       "200803                              97              193   \n",
       "200804                              27              171   \n",
       "200805                              25              202   \n",
       "\n",
       "        influenza_a_virus_subtype_h7n7       ...         fatigue_(medical)  \\\n",
       "200801                               6       ...                       957   \n",
       "200802                              12       ...                      1045   \n",
       "200803                              16       ...                       960   \n",
       "200804                              12       ...                       440   \n",
       "200805                               9       ...                      1174   \n",
       "\n",
       "        cat_flu  paracetamol  influenzavirus_a  influenza  \\\n",
       "200801      319        24246              1500      17568   \n",
       "200802      339        24699              2229      23338   \n",
       "200803      291        22948              2488      22742   \n",
       "200804      298        19869              3295      23488   \n",
       "200805      354        19414              4557      29240   \n",
       "\n",
       "        influenzalike_illness  human_flu  viral_neuraminidase  \\\n",
       "200801                      0        350                    0   \n",
       "200802                      0        453                    0   \n",
       "200803                      0        534                    0   \n",
       "200804                      0        577                    0   \n",
       "200805                      0        735                    0   \n",
       "\n",
       "        influenza_a_virus_subtype_h7n2  avian_influenza  \n",
       "200801                              14             3292  \n",
       "200802                              19             4870  \n",
       "200803                              25             5478  \n",
       "200804                              16             6522  \n",
       "200805                              14             6773  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'pageViews' not in definedVariables:\n",
    "    pageToViews = defaultdict(list)\n",
    "    pageViewsIndex = { week['epiweek'] for week in pageViewResps }\n",
    "    pageViewsIndex = list(pageViewsIndex)\n",
    "    pageViewsIndex.sort()\n",
    "\n",
    "    # map each article to it's weekly view counts (from 2008 to 2016)\n",
    "    for week in pageViewResps:\n",
    "        page, weeklyViews = week['article'], week['count']\n",
    "        pageToViews[page].append(weeklyViews)\n",
    "\n",
    "    pageViews = pd.DataFrame.from_dict(pageToViews, orient='index', dtype='int')\n",
    "    pageViews.fillna(0)\n",
    "    pageViews = pageViews.transpose()\n",
    "    # convert to ints, for some reasons transpose() coereces to floats\n",
    "    for column in pageViews.columns:\n",
    "        pageViews[column] = pageViews[column].fillna(0.0).astype('int')\n",
    "    pageViews.index = pageViewsIndex\n",
    "    pageViews[:2]\n",
    "    \n",
    "    %store pageViews\n",
    "else:\n",
    "    print(\"Found pageViews\")\n",
    "\n",
    "pageViews[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting ILInet API response in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found wILI\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weekly ILI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200801</th>\n",
       "      <td>2.254048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200802</th>\n",
       "      <td>2.091472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200803</th>\n",
       "      <td>2.359343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200804</th>\n",
       "      <td>3.323314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200805</th>\n",
       "      <td>4.433810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Weekly ILI\n",
       "200801    2.254048\n",
       "200802    2.091472\n",
       "200803    2.359343\n",
       "200804    3.323314\n",
       "200805    4.433810"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'wILI' not in definedVariables:\n",
    "    wILIvalues = [ week['ili'] for week in wILIresp ]\n",
    "    wILIindex = [ week['epiweek'] for week in wILIresp ]\n",
    "    wILIindex.sort()\n",
    "    wILI = pd.DataFrame(wILIvalues, columns=['Weekly ILI'], index=wILIindex)\n",
    "    wILI.drop([200853, 201453], inplace=True) # these epiweeks aren't in pageViews\n",
    "    \n",
    "    %store wILI\n",
    "else:\n",
    "    print(\"Found wILI\")\n",
    "wILI[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating DataFrame that maps Epiweek number to a datetime\n",
    "This will prove useful when doing timeseries analysis, as dealing with epiweeks (e.g. 200840) isn't ideal. This data is taken from \n",
    "> https://ibis.health.state.nm.us/resource/MMWRWeekCalendar.html\n",
    "\n",
    "Instead of sending a GET request, I have pasted the source html in the data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found epiweeksDf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-01-07</td>\n",
       "      <td>2007-01-06</td>\n",
       "      <td>2008-01-05</td>\n",
       "      <td>2009-01-10</td>\n",
       "      <td>2010-01-09</td>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>2012-01-07</td>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>2014-01-04</td>\n",
       "      <td>2015-01-10</td>\n",
       "      <td>2016-01-09</td>\n",
       "      <td>2017-01-07</td>\n",
       "      <td>2018-01-06</td>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>2020-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-01-14</td>\n",
       "      <td>2007-01-13</td>\n",
       "      <td>2008-01-12</td>\n",
       "      <td>2009-01-17</td>\n",
       "      <td>2010-01-16</td>\n",
       "      <td>2011-01-15</td>\n",
       "      <td>2012-01-14</td>\n",
       "      <td>2013-01-12</td>\n",
       "      <td>2014-01-11</td>\n",
       "      <td>2015-01-17</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>2017-01-14</td>\n",
       "      <td>2018-01-13</td>\n",
       "      <td>2019-01-12</td>\n",
       "      <td>2020-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-01-21</td>\n",
       "      <td>2007-01-20</td>\n",
       "      <td>2008-01-19</td>\n",
       "      <td>2009-01-24</td>\n",
       "      <td>2010-01-23</td>\n",
       "      <td>2011-01-22</td>\n",
       "      <td>2012-01-21</td>\n",
       "      <td>2013-01-19</td>\n",
       "      <td>2014-01-18</td>\n",
       "      <td>2015-01-24</td>\n",
       "      <td>2016-01-23</td>\n",
       "      <td>2017-01-21</td>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>2019-01-19</td>\n",
       "      <td>2020-01-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-01-28</td>\n",
       "      <td>2007-01-27</td>\n",
       "      <td>2008-01-26</td>\n",
       "      <td>2009-01-31</td>\n",
       "      <td>2010-01-30</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>2012-01-28</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>2014-01-25</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>2016-01-30</td>\n",
       "      <td>2017-01-28</td>\n",
       "      <td>2018-01-27</td>\n",
       "      <td>2019-01-26</td>\n",
       "      <td>2020-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2006-02-04</td>\n",
       "      <td>2007-02-03</td>\n",
       "      <td>2008-02-02</td>\n",
       "      <td>2009-02-07</td>\n",
       "      <td>2010-02-06</td>\n",
       "      <td>2011-02-05</td>\n",
       "      <td>2012-02-04</td>\n",
       "      <td>2013-02-02</td>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>2015-02-07</td>\n",
       "      <td>2016-02-06</td>\n",
       "      <td>2017-02-04</td>\n",
       "      <td>2018-02-03</td>\n",
       "      <td>2019-02-02</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        2006       2007       2008       2009       2010       2011  \\\n",
       "1 2006-01-07 2007-01-06 2008-01-05 2009-01-10 2010-01-09 2011-01-08   \n",
       "2 2006-01-14 2007-01-13 2008-01-12 2009-01-17 2010-01-16 2011-01-15   \n",
       "3 2006-01-21 2007-01-20 2008-01-19 2009-01-24 2010-01-23 2011-01-22   \n",
       "4 2006-01-28 2007-01-27 2008-01-26 2009-01-31 2010-01-30 2011-01-29   \n",
       "5 2006-02-04 2007-02-03 2008-02-02 2009-02-07 2010-02-06 2011-02-05   \n",
       "\n",
       "        2012       2013       2014       2015       2016       2017  \\\n",
       "1 2012-01-07 2013-01-05 2014-01-04 2015-01-10 2016-01-09 2017-01-07   \n",
       "2 2012-01-14 2013-01-12 2014-01-11 2015-01-17 2016-01-16 2017-01-14   \n",
       "3 2012-01-21 2013-01-19 2014-01-18 2015-01-24 2016-01-23 2017-01-21   \n",
       "4 2012-01-28 2013-01-26 2014-01-25 2015-01-31 2016-01-30 2017-01-28   \n",
       "5 2012-02-04 2013-02-02 2014-02-01 2015-02-07 2016-02-06 2017-02-04   \n",
       "\n",
       "        2018       2019       2020  \n",
       "1 2018-01-06 2019-01-05 2020-01-04  \n",
       "2 2018-01-13 2019-01-12 2020-01-11  \n",
       "3 2018-01-20 2019-01-19 2020-01-18  \n",
       "4 2018-01-27 2019-01-26 2020-01-25  \n",
       "5 2018-02-03 2019-02-02 2020-02-01  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'epiweeksDf' not in definedVariables:\n",
    "    \n",
    "    print(\"Creating epiweeks dataframe\")\n",
    "    \n",
    "    with open(\"data/epiweeks.html\") as f:\n",
    "        html = f.read().replace('\\n', '')\n",
    "        soup = BeautifulSoup( html, 'lxml' )\n",
    "        tables = soup.findAll(\"table\", {'class':'Info'})\n",
    "\n",
    "    epiweeksDf = pd.DataFrame()\n",
    "\n",
    "    for table in tables[::-1]:\n",
    "        rows = iter(table.findAll('tr'))\n",
    "        next(rows) # skip header\n",
    "        years = [int(year) for year in next(rows).text.split()]\n",
    "        df = pd.DataFrame(columns=years)\n",
    "        for i, row in enumerate(rows):\n",
    "            weeks = [ datetime.strptime(d, '%m/%d/%Y') for d in row.text.split()[1:] ]\n",
    "            if len(weeks) == 5:\n",
    "                df.loc[i+1] = weeks\n",
    "        epiweeksDf = pd.concat([epiweeksDf, df], axis=1)\n",
    "    %store epiweeksDf\n",
    "\n",
    "else:\n",
    "    print(\"Found epiweeksDf\")\n",
    "\n",
    "epiweeksDf[:5] "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:wikidemics]",
   "language": "python",
   "name": "conda-env-wikidemics-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
